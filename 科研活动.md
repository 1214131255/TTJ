# 1 文献阅读

​	

## 1.1 动机和创新点

动机：

• 大部分基于视频序列的多视角深度估计只使用当前帧和前一帧，没有充分利用多个相邻帧提供更丰富更可靠信息。

• 大部分方法使用3D正则化网络，将上下文与局部特征匹配信息混合学习，计算效率低

创新点：

• 提出了Epipolar Spatio-Temporal (EST) transformer，利用多个相邻帧的几何约束和时间相干性

• 使用2D ContextNet学习上下文信息，3D MatchNet学习局部匹配信息

## 1.2 网络框架

![image-20230327194254581](科研活动.assets/image-20230327194254581.png)

•包含Hybrid cost volume generation、Epipolar Spatio-Temporal Transformer、Depth extraction、Epipolar Spatio-Temporal Memory (ESTM)四个部分

•训练阶段输入为5帧视频序列，利用短时间一致性，估计目标图像{I_(t-1),I_t, I_(t+1)}的深度图；推理阶段， Epipolar Spatio-Temporal Memory (ESTM) 在整个视频中传播长时间一致性